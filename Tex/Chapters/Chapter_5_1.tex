\begin{itemize}
\item[3.] \[\frac{2}{\left( 1-x\right)^3}=\sum\limits_{n=2}^\infty n(n-1)\cdot x^{n-2},\hspace{5mm \abs{x}<1}\]
\end{itemize}

\begin{definition}{5.31}
\begin{enumerate}
\item $f:\Omega\to\R$ ist $m-$mal differenzierbar, falls $\underbrace{\left( \left( f'\right)'\dots\right)'}\limits_{m-\text{mal}}$ existiert. Die $m-$te iterierte Ableitung wird mit
\[f^{(m)}=\frac{\partial^m f}{\partial x^m}:\Omega\to\R\]
bezeichnet. Es gilt: $\forall k,l\geq 0$, $f^{\left(k+l\right)} = \left( f^{(k)}\right)^{\left(l\right)}$
\item $f$ ist in $C^m\left( \Omega\right)$, falls $f$ $m-$mal differenzierbar ist, und alle Funktionen $f=f^{(0)},f', f^{(2)}, \dots, f^{(m)}$ sind stetig
\item $f$ ist in $C^{\infty}\left( \Omega\right)$, falls $f\in C^m \left( \Omega\right)$, $\forall m \geq 0$
\end{enumerate}
\end{definition}

\subsubsection*{Korollar 5.32}
Unter den Voraussetzungen von Satz 5.29 \todo{Add reference}ist $f(x)=\sum\limits_{n=0}^\infty a_nx^n$ in $C^\infty\left( -\rho, \rho\right)$ und die Ableitungen von $f$ erhält man durch gliedweises differenzieren.
\subsubsection*{Formel}
\begin{align*}
f(x)&=\sum\limits_{n=0}^\infty a_nx^n, x\in\left( -\rho,\rho\right)\\
f'(x)&=\sum\limits_{n=0}^\infty na_nx^n\\
\vdots\\
f^{(k)}(x)&=\sum\limits_{n=0}^\infty a_n(n)\cdot(n-1)\dots(n-k+1)\cdot x^{n-k}\\
\Aboxed{f^{(k)}(x)&=\sum\limits_{n=k}^\infty a_n\frac{n!}{\left( n-k\right)!} x^{n-k}}
\end{align*}

\section{Taylorformel}
Wir beginnen, als Motivation, mit Polynomen. Sei
\[P(x)=a_0+a_1x+a_2x^2+\dots+a_nx^n\]
ein Polynom, grad $P\leq n$. Durch $x=(x-a)+a$ und Umordnen nach Potenzen von $(x-a)$ erhalten wir
\[p(x)=b_0+b_1(x-a)+b_2(x-a)^2+\dots+b_n(x-a)^n\]

\subsubsection*{Beispiel}
$p(x)=x^3+x+1$. Sei $a=1$:
\begin{align*}
p(x)&=\left( \left( x-1\right)+1\right)^3 +\left( x-1\right)+1+1\\
&=\left( x-1\right)^3+3\left( x-1\right)^2+\left( x-1\right)+1+\left( x-1\right)+2\\
&=\left( x-1\right)^3+3\left( x-1\right)^2+4\left( x-1\right)+3
\end{align*}

Wir bestimmen jetzt die Koeffizienten $b$:
\begin{align*}
p(a)&=b_0\\
p'(x)&=b_1+2b_2(x-a)+\dots+nb_n(x-a)\Rightarrow p'(a)=b_1\\
p''(x)&=2b_2+6b_3(x-a)+\dots+n(n-1)(x-a)^{n-2}\Rightarrow p''(a)=2b_2\\
\end{align*}
Rekursiv: $p^{(j)}(a)=j!b_j$ mit der Konvention $b_j=0$ für $j\geq n+1$ da $p^{(n+1)}=0$. Es folgt:
\[p(x)=p(a)+p'(a)(x-a)+\frac{p''(a)}{2!}(x-a)^2+\dots+\frac{p^{(n)}(a)}{n!}\left( x-a\right)^n\]

\subsubsection*{Beispiel}
\begin{align*}
p(x)&=x^3+x+1 \hspace{5mm}p(1)=3\\
p'(x)&=3x^2+1\hspace{8.5mm} p'(1)=4\\
p''(x)&=6x \hspace{15.2mm} p''(1)=6, \frac{p''(1)}{2!}=3\\
p'''(x)&=6 \hspace{16mm} p'''(1)=6, \frac{p'''(1)}{3!}=1\\
\end{align*}
\[p(x)=3+4(x-1)+3(x-1)^2+(x-1)^3\]
Folgendes ist dann naheliegend

\subsubsection*{Satz 5.33}
Sei $\lbrack a,b\rbrack\subset \Omega\subset\R$ und $f\in C^{m-1}\left( \Omega\right)$, $m-$mal differenzierbar auf $\Omega$. Dann gibt es $c\in(a,b)$:
\[f(b)=f(a)+f'(a)(b-a)+\dots+f^{m-1}(a)\frac{(b-a)^{m-1}}{(m-1)!}+\frac{f^m(c)}{m!}(b-a)^m\]

\begin{beweis}{}
Wir betrachten die Funktion
\[g(x)=f(x)+f'(x)(b-x)+\dots+\frac{f^{m-1}(x)(b-x)^{m-1}}{(m-1)!}+\frac{K(b-x)^m}{m!}-f(b)\]
die auf $\Omega$ differenzierbar ist. Dann ist $g(b)=0$. Wähle $K$ so dass $g(a)=0$. Dann gibt es $c\in (a,b)$ mit $g'(c)=0$. Wir berechnen jetzt $g'(x)$:
\[g'(x)=f'(x)+\dots \left( \frac{f^{(j)}(x)(b-x)^j}{j!}\right)'+\dots+K\frac{m(b-x)^{m-1}}{m!}\]
Nun ist
\[\left( \frac{f^{(j)}(x)(b-x)^j}{j!}\right)'=\frac{f^{(j)}(b-x)^{j-1}}{(j-1)!}(-1)+\frac{f^{(j+1)}(x)(b-x)^{j}}{j!}\]
Woraus folgt:

\begin{align*}
g'(x)=&f'(x)\\
&+\left\{ -f'(x)+\frac{f^{(2)}{(x)(b-x)}}{1!}\right\}\\
&+\left\{ -\frac{f^{(2)}(x)(b-x)}{1!}+ \frac{f^{(3)}(x)(b-x)^2}{2!} \right\}\\
&\hspace{2mm}\vdots\\
&+\left\{ -\frac{f^{(m-1)}(x)(b-x)^{(m-2)}}{(m-2)!}+ \frac{f^{(m)}(x)(b-x)^{m-1}}{(m-1)!} \right\}\\
&-K\frac{(b-x)^{m-1}}{(m-1)!}
\end{align*}
Also: \[g'(x)=\left[ f^{(m)}(x)-K\right]\frac{(b-x)^{m-1}}{(m-1)!}\]
Aus $g'(c)=0$ folgt $\boxed{f^m(c)=K}$ und $g(a)=0$ nimmt folgende Form an:
\[g(a)=0=f(a)+f'(a)(b-a)+\dots+\frac{f^{m-1}(c)(b-a)^{m-1}}{(m-1)!}+\frac{f^m(c)}{m!}(b-a)^m-f(b)\]
\end{beweis}

\subsubsection*{Korollar 5.34}
Sei $f:(c,d)\to\R$ $m-$mal differenzierbar, seien $x_0,x\in (c,d)$. Dann gibt es $\xi\in (x_0,x)$ mit
\begin{align*}
f(x)=&f(x_0)+f'(x_0)(x-x_0)\\
&\vdots \\
&+f^{m-1}(x_0)\frac{(x-x_0)^{m-1}}{(m-1)!}\\
&+\frac{f^m(\xi)(x-x_0)^m}{m!}
\end{align*}
Wir führen folgende Terminologie ein:
\[T_mf(x;x_0) = f(x_0)+\dots+f^{(m)}(x_0)\frac{(x-x_0)^m}{m!}\]
ist das Taylor Polynom $n-$ter Ordnung. $\left( f\in C^m\right)$ und
\[R_mf(x;x_0):=f(x)-T_mf(x;x_0)\]
ist der Restterm. \\

Falls $f(m+1)-$mal differenzierbar in $\Omega$ ist, so ist
\[R_mf(x;x_0)=f^{(m+1)}(\xi)\frac{\left( x-x_0\right)^{m+1}}{(m+1)!}, \xi\in\left( x_0,x_0\right)\]

\subsubsection*{Bemerkung}
Bei der Differenzierbarkeit haben wir gesehen, dass die lineare Funktion $f'(a)+f'(a)(x-a)$ im folgenden Sinne eine gute Approximation der Funktion $f(x)$ darstellt: Es gilt
\[f(x)=f(c)+f'(a)(x-a)+R_1f(x;a) = T_1f(x;a)+R_1f(x;a)\]
und
\[\lim\limits_{x\to a}\frac{R_1f(x;a)}{x-a} = \lim\limits_{x\to a}\left(\frac{f(x)-f(a)}{x-a}-f'(a)\right)=0\]
Die Taylorformel gibt nun an, wie mann diese Approximation noch verbessern kann.
\[f(x) = \underbrace {{T_m}f(x;a)}_{{\text{Approximation}}} + \underbrace {{R_m}f(x;a)}_{{\text{fehler}}}\]
Für diesen Fehler gilt:
\[\lim\limits_{x\to a}\frac{R_mf(x;a)}{(x-a)^m}=0\tag{\textasteriskcentered}\]
Das bedeutet, dass wenn $x$ nahe bei $a$ ist, $R_mf(x;a)$ klein ist im Vergleich zu der schon sehr kleinen Grösse $(x-a)^m$. 

\[f(x) = f(a)+\dots+\frac{f^{m-1}(a)(x-a)^{m-1}}{(m-1)!}+\frac{f^{m}(\xi)(x-a)^{m}}{(m)!}\]
\begin{align*}
f(x) + \frac{f^{m}(a)(x-a)^{m}}{(m)!} &= T_m f(x;a)+\frac{f^{m}(\xi)(x-a)^{m}}{(m)!}\\
\Rightarrow f(x)-T_mf(x;a) &= \frac{f^m (\xi) -f^m(a)}{m!}(x-a)^m
\end{align*}

Für den Restterm $R_mf(x;a)$, haben wir somit die Abschätzung 

\[R_mf(x;a) = f(x)-T_mf(x;a) = \left[ f^m(\xi) -f^m(a)\right]\frac{(x-a)^m}{m!}\]

\[\abs{R_mf(x;a)}<\sup\limits_{a<\xi<x}\abs{f^{(m)}(\xi)-f^m(a)}\frac{(x-a)^m}{m!}\]
Falls $f\in C^{m+1}$, können wir denn Mittelwertsatz anwenden. Dann folgt:
\begin{align*}
\abs{R_mf(x;a)}&\leq\left( \sup\limits_{a<\xi<x}\abs{f^{(m+1}(\xi)}\right)\abs{x-a}\frac{(x-a)^m}{m!}\\
&\leq M\frac{(x-a)^{m+1}}{m!}\\
\Rightarrow & \abs{\frac{R_mf(x-a)}{(x-a)^m}}\to 0, x\to a
\end{align*}

\subsubsection*{Beispiel 5.35}
\begin{center}
\begin{tabular}{r l}
$\begin{aligned}
f(x)&=\sin(x)\\
f'(x)&=\cos(x)\\
f''(x)&=-\sin(x)\\
f'''(x)&=-\cos(x)\\
f^4(x)&=\sin(x)\\
f^5(x)&=\cos(x)\\
\end{aligned}$&
$\begin{aligned}
x_0&=0\\
f'(0)&=1\\
f''(0)&=0\\
f'''(0)&=-1\\
f^4(0)&=0\\
^5(0)&=1\\
\end{aligned}$
\end{tabular}
\end{center}
Also
\begin{align*}
\sin x &= x-\frac{x^3}{3!}+\frac{\cos(\xi)}{5!}x^5\\
T_1(x)&=x=T_2(x)\\
T_3(x)&=x-\frac{x^3}{3}=T_4(x)
\end{align*}
Insbesondere
\[\abs{\sin(x)-x+\frac{x^3}{3}}\leq \frac{x^5}{5!}\]
liefert für ein kleines $\abs{x}$ eine sehr gute Approximation von, zum Beispiel, $x=\frac{1}{10}$
\[\abs{\sin\left( \frac{1}{10}\right)-\frac{1}{10}+\frac{1}{1000}}<\frac{1}{10^5\cdot 5!}\]
\[\sin\left( \frac{1}{10}\right)\approx \frac{1}{10}-\frac{1}{1000}=0.1-0.001=0.099\]

\subsection*{Lokale Extrema}
Wir haben den folgenden Satz schon gesehen:

\subsubsection*{Satz 5.12}
Sei $f:\lbrack a,b\rbrack\to\R$ stetig und auf $(a,b)$ differenzierbar. Sei $z_+\in( a,b)$ mit $f(z_+)=\max\left\{ f(x):x\in\lbrack a,b\rbrack\right\}$. Dann gilt $f'(z_+)=0$\\

\noindent Mittels Taylorformel können wir lokale Extrema (Maxima und Minima) diskutieren. \\

\noindent Sei $\Omega\subseteq\R$, $f:\Omega\to\R, x_0\in\Omega$

\begin{definition}{5.38}
\begin{enumerate}
\item $x_0\in\Omega\subset\R$ heisst lokale Maximalstelle (bzw. Minimalstelle) von $f$, falls es $r>0$ gibt s.d. $\forall x\in B_r(x_0)$, $f(x)\leq f(x_0)$ (resp. $f(x)\geq f(x_0)$, $\forall x\in B_r(x_0)$).
\item Die lokale Minimalstelle (bzw. Maximalstelle) heisst \emph{strikt}, falls $f(x)>f(x_0)$ (bzw. $f(x)<f(x_0)$)
\item Eine lokale Extremalstelle ist entweder lokale Minimalstelle oder Maximalstelle.
\end{enumerate}
\end{definition}
Falls $f$ an einer lokalen Minimalstelle $x_0$ differenzierbar ist, so folgt wie im Beweis von Satz 5.12 \todo{Maybe add a reference?}
\[0\leq \lim\limits_{x\downarrow x_0}\frac{f(x)-f(x_0)}{x-x_0}=f'(x_0)=\lim\limits_{x\to x_0}\frac{f(x)-f(x_0)}{x-x_0}\leq 0\]
Also $f'(x_0)=0$. Allgemein gilt:
\subsubsection*{Satz 5.39}
Sei $\Omega\subset\R$, $f:\Omega\to\R$, $f\in C^{\infty}\left( \Omega\right)$, $x_0\in\Omega$. Dann tritt einer der folgenden Fälle ein
\begin{enumerate}
\item $f^j(x_0)=0$, $\forall j\geq 1$
\item $m:=1+\max\left\{ j:f^i(x_0)=0, 1\leq i\leq j \right\} <+\infty $, d.h. $f^m(x_0)\not=0$, und $f^{(1)}(x_0)=0=f^{(2)}(x_0)=\dots=f^{(n-1)}(x_0)=$\todo{Chopped content, page 244 top}
\begin{enumerate}
\item[\hspace{4mm}(2.1)] $m$ ist ungerade, dann ist $x_0$ kein Extremalstelle.
\item[\hspace{4mm}(2.2)] $m$ ist gerade und $f^m(x_0)>0$, dann ist $x_0$ eine strikte lokale Minimalstelle
\item[\hspace{4mm}(2.3)] $m$ ist gerade und $f^m(x_0)<0$, dann ist $x_0$ eine strikte lokale Maximalstelle
\end{enumerate}
\end{enumerate}

\begin{beweis}{}
Falls (1.) nicht eintritt, so tritt (2.) ein. Also sei \[f^{(1)}(x_0)=f^{(2)}(x_0)=\dots=f^{(m-1)}(x_0)=0\text{ und }f^{(m)}(x_0)\not=0\]
Jetzt wenden wir Taylorformel an
\[f(x)=f(x_0)+f'(x_0)(x-x_0)+\dots+\frac{f^{m-1}(x_0)}{m!}(x-x_0)^m+\frac{f^{m}(\xi)}{m!}(x-x_0)^m\]
für ein $\xi\in(x,x_0)$. Aus $f'(_0)=\dots=f^{m-1}(x_0)=0$ folgt
\[f(x)=f(x_0)+f^m(\xi)\frac{(x-x_0)^m}{m!}, \xi\in(x,x_0)\]
\begin{enumerate}
\item[\hspace{4mm}(2.1)] $m$ ist ungerade: Falls $f$ an $yx_0$ ein lokales Minimum hat, so folgt
\[{f^m}({x_0})\mathop  = \limits^{{f^m}{\text{ stetig}}} \mathop {\lim }\limits_{\xi  \to {x_0}} {f^m}(\xi ) = \mathop {\lim }\limits_{\xi  \to {x_0}} \frac{{f(x) - f({x_0})}}{{{{(x - {x_0})}^m}}} \cdot m!\]
Da $m$ ungerade ist
\[\begin{array}{*{20}{c}}
{{{(x - {x_0})}^m} > 0,x > {x_0}}\\
{{{(x - {x_0})}^m} < 0,x < {x_0}}
\end{array}=\begin{cases}
\lim\limits_{x\downarrow x_0}\frac{f(x)-f(x_0)}{(x-x_0)^m}\cdot m! & \geq 0\\
\lim\limits_{x\uparrow x_0}\frac{f(x)-f(x_0)}{(x-x_0)^m}\cdot m! & \leq 0
\end{cases}\]
$\Rightarrow f^m(x_0)=0$ . Widerspruch zur $f^m(x_0)\not=0$. Analog für $x_0$ lokale Maximalstelle
\item[\hspace{4mm}(2.2)] Falls $m$ gerade ist, und $f^m(x_0)>0$ dann folgt aus
\[0<f^m(x_0)=\lim\limits_{\xi\to x_0}\frac{f(x)-f(x_0)}{(x-x_0)^m}\cdot m!\]
dass für $x\in(x_0-\epsilon, x_0+\epsilon)$, $x\not=x_0$, $f(x)-f(x_0)>0\Rightarrow f(x)>f(x_0)$, $x_0$ ein lokales Minimum.
\item[\hspace{4mm}(2.3)] $m$ ist gerade,  $f^m(x_0)<0$, analog.
\end{enumerate}
\end{beweis}

\subsubsection*{Graphen}
\begin{enumerate}
\item[\hspace{4mm}(2.1)] $m=3$
\begin{center}
\begin{tikzpicture}[scale=0.6]
\node [] (0) at (0, 4.5) {};
\node [] (1) at (0, -1) {};
\node [] (2) at (-1, 0) {};
\node [] (3) at (4.5, 0) {};
\node [] (4) at (0.5, 0.5) {};
\node [] (5) at (3.5, 3.5) {};

\draw [->] (1.center) to (0.center);
\draw [->] (2.center) to (3.center);
\draw [, in=-105, out=60, looseness=1.75] (4.center) to (5.center);

\newcommand{\spaceTikz}{8}

\node [] (6) at (\spaceTikz+0, 4.5) {};
\node [] (7) at (\spaceTikz+0, -1) {};
\node [] (8) at (\spaceTikz+-1, 0) {};
\node [] (9) at (\spaceTikz+4.5, 0) {};
\node [] (10) at (\spaceTikz+3.5, 0.5) {};
\node [] (11) at (\spaceTikz+0.5, 3.5) {};

\draw [->] (7.center) to (6.center);
\draw [->] (8.center) to (9.center);
\draw [, in=-70, out=120, looseness=1.75] (10.center) to (11.center);
\end{tikzpicture}
\end{center}

\item[\hspace{4mm}(2.2)] {$m=2$ 
\begin{multicols}{2}
\begin{tikzpicture}[scale=0.75]
\draw[->](-0.5,0) -- (6,0);
\draw[->](0,-0.5) -- (0,4);
\draw (1,3) parabola bend (3,1) (5,3);
\draw[dashed] (3,1) -- (3,0) node [anchor=north] {$x_0$};
\draw (1,-0.75) node [anchor=north west]{$f''(x_0)>0$};
\end{tikzpicture}
\columnbreak
\begin{align*}
f(x)&=(x-x_0)^2+c\\
f'(x)&=2(x-x_0)\\
f''(x)&=2>0 \\
\end{align*}
\end{multicols}}

\item[\hspace{4mm}(2.3)] $m=2$
\begin{multicols}{2}
\begin{tikzpicture}[scale=0.75]
\draw[->](-0.5,0) -- (6,0);
\draw[->](0,-0.5) -- (0,4);
\draw (1,0) parabola bend (3,2) (5,0);
\draw[dashed] (3,2) -- (3,0) node [anchor=north] {$x_0$};
\draw (1,-0.75) node [anchor=north west]{$f''(x_0)<0$};
\end{tikzpicture} 
\columnbreak
\begin{align*}
f(x) &= 1-(x-x_0)^2 \\
f'(x) &= 2(x_0 - x) \\
f''(x) &= -2 < 0
\end{align*}
\end{multicols}
\end{enumerate}
Für $m$ ungerade $\geq 3$ spricht man von einem Wendepunkt.

\subsubsection*{Beispiel 5.40}
\begin{enumerate}
\item Der Fall (1.) tritt man ein z.B. $f(x)=e^{-\frac{1}{x^2}}$, $x\in\R$ ist auf ganz $\R$ $C^\infty$ und $f^{(j)}(0)=0$, $\forall j\geq 1$
\item \begin{align*}
f(x)&=x^4-x^2+1\hspace{5mm} f\left(\pm\frac{1}{\sqrt{2}}\right)=\frac{1}{4}-\frac{1}{2}+1=\frac{3}{4}\\
f'(x)&=4x^3-2x=2x(2x^2-1)=0 \Leftrightarrow x\in\left\{\pm\frac{1}{\sqrt{2}}, 0\right\}\\
f''(x)&=12x^2-2\\
f'''(0)&=-2<0\Rightarrow x_0=0\text{ Lokale Maximalstelle}\\
f''''\left(\pm\frac{1}{\sqrt{2}}\right)&=4>0\Rightarrow x_0=\pm\frac{1}{\sqrt{2}}\text{ Lokale Minimalstelle}
\end{align*}
\begin{center}
\begin{tikzpicture}[domain=-1.2:1.2, scale=2]
\draw[] plot[id=x,samples=100] function{x**4-x**2+1};
\draw[->] (-1.75,0.5)--(1.75,0.5);
\draw[->] (0,0.2)--(0,1.75);
\draw[dashed](-0.707,0.75)--(0.707,0.75);
\draw[fill=black] (0,1) circle (0.025);
\draw[dashed](0.707,0.75)--(0.707,0.5) node [anchor=north]{$\frac{1}{\sqrt{2}}$};
\draw[dashed](-0.707,0.75)--(-0.707,0.5) node [anchor=north]{$-\frac{1}{\sqrt{2}}$};
\draw (0,1) node [anchor=south east]{1};
\draw (0,0.5) node [anchor=north west]{0};
\draw (0,0.75) node [anchor=north west]{\tiny$3/4$};
\end{tikzpicture}
\end{center}
\item {Minimierungseigenschaft des arithmetischen Mittels:}\\
Seien $a_1,a_2,\dots,a_n\in\R$. Wir suchen $x_0\in\R$, so dass
\[f(x_0)=\sum\limits_{i=1}^n\left( x_0-a_i\right)^2\]
minimal ist. Sei
\[f(x)=\sum\limits_{i=1}^n\left( x-a_i\right)^2=nx^2-2Ax+B\]
wobei
\[A=\sum\limits_{i=1}^n a_i\hspace{10mm}B=\sum\limits_{i=1}^n a_i^2\]
$f(x)\to\infty$ für $\abs{x}\to\infty$. Also gibt es $x_0\in\R$ mit $f(x_0)=\min f$. Sei $x_0$ eine solche. Dann folgt $f'(x_0)=0$ d.h.
\[\sum\limits_{i=1}^n2\left( x_0-a_i\right)=0=2\sum\limits_{i=1}^n x_j -\sum\limits_{i=1}^na_i\]
d.h.
\[nx_0=\sum\limits_{i=1}^n a_i\Rightarrow x_0=\frac{1}{n}\sum a_i\]
Nun ist $f''(x)=2n>0$, folglich ist $\frac{1}{n}\sum\limits_{i=1}^n a_i=x_0$ die gesuchte Minimalstelle.
\end{enumerate}

\subsection*{Konvexe Funtionen}
Eine einfache und geometrische Eigenschaften einer Funktion ist Konvexität: Für $C^2$ Funktionen kann Konvexität mittels der zweiten Ableitung getestet werden

\begin{definition}{5.41}
$f:(a,b)\to\R$ ist konvex, falls $\forall x_0\leq x_1$ und $t\in\lbrack 0,1\rbrack$
\[f\left( tx_0+(1-t)x_1\right)\leq tf(x_0)+(1-t)f(x_1)\]
\end{definition}
\missingfigure{Page 249, rather complex...}

Der Graph der Funktion $f$ liegt unterhalb jeder Verbindungsstrecke zweier seiner Punkte.

\subsubsection*{Satz 5.42}
Sei $f:(a,b)\to\R$ der Klasse $C^2$, mit $f''(x_0)\geq 0$, $\forall x\in (a,b)$. Dann ist $f$ konvex.

\begin{beweis}{}
Seien $x_0<x_1$ in $(a,b)$
\begin{center}
\begin{tikzpicture}
\node [] (0) at (0, 3.5) {};
\node [] (1) at (0, 0) {};
\node [] (2) at (0, 0) {};
\node [] (3) at (5, 0) {};
\node [] (4) at (0.5, 1) {};
\node [] (5) at (4, 3) {};
\draw [->] (1.center) to (0.center);
\draw [->] (2.center) to (3.center);
\draw [, in=-120, out=-15] (4.center) to (5.center);

\draw[dashed] (1,0) -- (1,0.91);
\draw[fill=black] (1,0.91) circle (0.035);

\draw[dashed] (3.75,0) -- (3.75,2.6);
\draw[fill=black] (3.75,2.6) circle (0.035);

\draw (3.75,0) node [anchor=north] {$x_1$};
\draw (1,0) node [anchor=north] {$x_0$};
\end{tikzpicture}
\end{center}
Wir betrachten
\begin{align*}
g:\lbrack 0,1\rbrack&\to\R\\
t&\mapsto f\left( tx_0+(1-t)x_1\right) = tf(x_0)-(1-t)f(x_1)
\end{align*}
Dann gilt $g(0)=g(1)=0$ und
\[g''(t)=f\left( tx_0+(1-t)x_1\right)(x_0-x_1)^2\geq 0\]
(Wir möchten beweisen, dass $g\leq 0$). Falls es $t$ gibt mit $g(t)>0$, dann ist $\max\limits_{t\in\lbrack 0,1\rbrack} g(t)>0$\\

\noindent Sei $t_0$ so dass
\[g(t_0)=\max\limits_{t\in\lbrack 0,1\rbrack} g(t)>0\]
Offensichtlich ist $g'(t_0)=0$. Nun betrachten wir die lineare Taylor entwicklung von $g$ im Punkte $t_0$, es gibt $\xi\in(t_0,1)$ mit
\[0=g(1)=g(t_0)+g'(t_0)(1-t_0)+\frac{{\overbrace {g''(\xi )}^{ > 0}\overbrace {(1 - {t_0})}^{ > 0}}}{{2!}}\geq g(t_0)>0\]
Ein Wiederspruch. Also ist $g(t)<0$, $\forall t\in\lbrack 0,1\rbrack$ und $f$ ist konvex
\end{beweis}

\subsubsection*{Beispiel 5.43}
\begin{enumerate}
\item $\exp$ ist konvex in $\R$, $f''(x)=\exp x>0$
\item $f(x)=-\ln x$, $x>0$. $f'(x)=-\frac{1}{x}$, $f''(x)=\frac{1}{x^2}>0$
\item $f(x)=x\ln x$, $x>0$. $f'(x)=\ln x +1$, $f''(x)=\frac{1}{x}$
\item $f(x)=x^\alpha $, $f'(x)=\alpha x^{\alpha-1}$ $x>0$. $f''(x)=\alpha(\alpha-1)x^{\alpha-2}>0\Leftrightarrow \alpha >1$
\end{enumerate}

\subsubsection*{Satz 5.44}
Sei $f:(a,b)\to\R$ konvex. Für alle $x_1,\dots,x_n\in(a,b)$ und $t_1,\dots,t_n\in\lbrack 0,1\rbrack$ mit $\sum\limits_{i=1}^n t_i=1$ gilt
\[f\left( \sum\limits_{i=1}^n t_ix_i\right)\leq  \sum\limits_{i=1}^n t_if(x_i)\]

\subsubsection*{Korollar 5.45}
Seien $x_1,\dots, x_n\in (0,\infty)$, $\alpha_1,\dots,\alpha_n\in\lbrack 0,1\rbrack$ mit $\sum\alpha_i=1$. Dann gilt
\[\prod\limits_{i = 1}^n {x_i^{{\alpha _i}}}  \le \sum\limits_{i = 1}^n {{\alpha _i}{x_i}} \]
Insbesondere $\left( \alpha_i=\frac{1}{n}, i\leq r\leq n\right)$
\[{\left( {\prod\limits_{i = 1}^n {{x_i}} } \right)^{\frac{1}{n}}} \le \frac{1}{n}\sum\limits_{i = 1}^n {{x_i}} \]
\todo{Add as an appendix or something page 253.1}

\begin{beweis}{}
Die Funktion $\exp$ ist konvex. Nun schreiben wir
\begin{align*}
\prod\limits_{i = 1}^n {x_i^{{\alpha _i}}}  &= \prod\limits_{i = 1}^n {\exp ({\alpha _i}\ln {x_i})} \\
&=\exp\left( \sum\limits_{i=1}^n \alpha_i \ln x_i\right)\\
&\leq \sum\limits_{i=1}^n \alpha_i \exp\left(\ln x_i\right)\\
&=\sum\limits_{i=1}^n\alpha_i x_i
\end{align*}
\end{beweis}

\begin{beweis}{5.44}
Induktion über $n\geq 1$.\\
\begin{itemize}
\item Für $n=1$ steht $f(1\cdot x_1)\leq 1\cdot f(x_1)$ \checkmark
\item Für $n=2$ ist es die Definition der Konvexität.
\item Sei nun $n\geq 3$. Wir können annehmen dass $t_1\not=1$. (Ansonsten sind alle $t_1=0$, $\forall i\geq 2$ und die Ungleichung ist trivial). Nun schreiben wir
\[\sum\limits_{k = 1}^n {{t_k}{x_k}}  = {t_1}{x_1} + \left( {1 - {t_1}} \right) \cdot \left( {\frac{{\sum\limits_{k = 2}^n {{t_k}{x_k}} }}{{1 - {t_1}}}} \right)\]
Aus Konvexität folgt dann
\[f\left( \sum t_kx_k \right)\leq t_1f(x_1)+\left( 1-t_1\right)\cdot f\left( \sum\limits_{k=2}^n \frac{t_k x_k}{1-t_1}\right)\]
Nun sind $x_2,x_3,\dots, x_n$, $(n-1)$ Punkte. Die Koeffizienten $\frac{t_2}{1-t_1},\frac{t_3}{1-t_1},\dots,\frac{t_n}{1-t_1}$ sind alle $\geq 0$, und deren Summe
\[\sum\limits_{k = 2}^n {\frac{{{t_k}}}{{1 - {t_1}}}}  = \frac{1}{{1 - {t_1}}}\sum\limits_{k = 2}^n {{t_k}}  = \frac{{1 - {t_1}}}{{1 - {t_1}}} = 1\]
Jetzt kann man die Induktionsannahme anwenden
\begin{align*}
f\left( \sum\limits_{k = 1}^n {{t_k}{x_k}} \right)&\leq t_1f(x_1)+\left( 1-t_1\right)\cdot f\left( \sum\limits_{k = 2}^n \frac{t_k}{1-t_1}x_k\right)\\
&\leq t_1f(x_1)+\left( 1-t_1\right)\cdot\sum\limits_{k = 2}^n \left(\frac{t_k}{1-t_1}\right)\cdot f(x_k)\\
&= t_1f(x_1)+\sum\limits_{k = 2}^n t_k f(x_k)\\
\end{align*}
\end{itemize}
\end{beweis}

\newpage
\subsubsection*{Appendix A: Vergleich von arithmetischen und geometrischen Mittel}
Arithmetic Geometric Mean (AGM) \\
$n=2:$
\begin{align*}
\frac{x_1+x_2}{2}&\geq\sqrt{x_1\cdot x_2}\\
\Rightarrow 2(x_1+x_2)&\geq 4\sqrt{x_1\cdot x_2}
\end{align*}
Ein Rechteck mit dem Seiten $x_1$ und $x_2$ hat den Gesamtumfang $2x_1+2x_2$. Ein Quadrat mit dem gleichen Flächeninhalt hat den Umfang $4\sqrt{x_1\cdot x_2}$\\

AGM sagt, dass unter allen Rechtecken mit gleichem Inhalt $A=x_1\cdot x_2$, das Quadrat den kleinsten Umfang hat.




